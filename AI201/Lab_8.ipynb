{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78eea55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io # We will use this to simulate file I/O\n",
    "import os # To clean up created files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Series from dictionary ---\n",
      "name       Alice\n",
      "age           30\n",
      "city    New York\n",
      "dtype: object\n",
      "\n",
      "Value for 'age': 30\n",
      "\n",
      "--- Attributes ---\n"
     ]
    }
   ],
   "source": [
    "# series\n",
    "# it is a single column with an index, it can be created from list array or dictionary\n",
    "\n",
    "\n",
    "pd.Series(['Alice', 30, 'New York'], index=['name', 'age', 'city'])\n",
    "\n",
    "\n",
    "\n",
    "# Creating a Series from a dictionary\n",
    "s_dict = pd.Series({'name': 'Alice', 'age': 30, 'city': 'New York'})\n",
    "print(\"\\n--- Series from dictionary ---\")\n",
    "print(s_dict)\n",
    "print(\"\\nValue for 'age':\", s_dict['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d65caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Attributes ---\n",
      "Index: Index(['name', 'age', 'city'], dtype='object')\n",
      "Values: ['Alice' 30 'New York']\n",
      "Data Type: object\n"
     ]
    }
   ],
   "source": [
    "# Series attributes\n",
    "\n",
    "print(\"\\n--- Attributes ---\")\n",
    "print(\"Index:\", s_dict.index)\n",
    "print(\"Values:\", s_dict.values)\n",
    "print(\"Data Type:\", s_dict.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4418e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame from Dictionary ---\n",
      "      Name  Age         City  Salary\n",
      "0    Alice   25     New York   70000\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "# it is a 2D table with rows and columns, it can be created from list of lists, dictionary of lists or 2D array\n",
    "\n",
    "# columns: the label of the vertical data\n",
    "# index: the label of the horizontal rows\n",
    "\n",
    "# Creating a DataFrame from a dictionary of lists (most common)\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "    'Salary': [70000, 80000, 90000, 100000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- DataFrame from Dictionary ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c423df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame with Custom Index ---\n",
      "         Name  Age         City  Salary\n",
      "emp1    Alice   25     New York   70000\n",
      "emp2      Bob   30  Los Angeles   80000\n",
      "emp3  Charlie   35      Chicago   90000\n",
      "emp4    David   40      Houston  100000\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with a custom index\n",
    "df_custom_index = pd.DataFrame(data, index=['emp1', 'emp2', 'emp3', 'emp4'])\n",
    "print(\"\\n--- DataFrame with Custom Index ---\")\n",
    "print(df_custom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7e81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Attributes ---\n",
      "Index: RangeIndex(start=0, stop=4, step=1)\n",
      "Columns: Index(['Name', 'Age', 'City', 'Salary'], dtype='object')\n",
      "Data Types:\n",
      " Name      object\n",
      "Age        int64\n",
      "City      object\n",
      "Salary     int64\n",
      "dtype: object\n",
      "Shape (rows, cols): (4, 4)\n",
      "Values (as NumPy array):\n",
      " [['Alice' 25 'New York' 70000]\n",
      " ['Bob' 30 'Los Angeles' 80000]\n",
      " ['Charlie' 35 'Chicago' 90000]\n",
      " ['David' 40 'Houston' 100000]]\n"
     ]
    }
   ],
   "source": [
    "# DataFrame attributes\n",
    "print(\"\\n--- Attributes ---\")\n",
    "print(\"Index:\", df.index)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Data Types:\\n\", df.dtypes)\n",
    "print(\"Shape (rows, cols):\", df.shape)\n",
    "print(\"Values (as NumPy array):\\n\", df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b190c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Read from CSV ---\n",
      "    id   name department   salary\n",
      "0  101   John      Sales  50000.0\n",
      "1  102   Jane  Marketing  60000.0\n",
      "2  103  Peter      Sales  55000.0\n",
      "3  104   Mary         HR  45000.0\n",
      "4  105    Tom        NaN  70000.0\n",
      "5  106   Lisa  Marketing      NaN\n",
      "\n",
      "--- Read from CSV with options ---\n",
      "      name department   salary\n",
      "id                            \n",
      "101   John      Sales  50000.0\n",
      "102   Jane  Marketing  60000.0\n",
      "103  Peter      Sales  55000.0\n",
      "104   Mary         HR  45000.0\n",
      "105    Tom        NaN  70000.0\n",
      "106   Lisa  Marketing      NaN\n"
     ]
    }
   ],
   "source": [
    "# First, let's create a dummy CSV file to read\n",
    "csv_data = \"\"\"id,name,department,salary\n",
    "101,John,Sales,50000\n",
    "102,Jane,Marketing,60000\n",
    "103,Peter,Sales,55000\n",
    "104,Mary,HR,45000\n",
    "105,Tom,,70000\n",
    "106,Lisa,Marketing,\n",
    "\"\"\"\n",
    "\n",
    "# We use io.StringIO to simulate reading a file from disk\n",
    "# In real life, you would just use the file path:\n",
    "# df_csv = pd.read_csv('my_file.csv')\n",
    "\n",
    "df_csv = pd.read_csv(io.StringIO(csv_data))\n",
    "\n",
    "print(\"--- Read from CSV ---\")\n",
    "print(df_csv)\n",
    "\n",
    "# Common parameters for read_csv:\n",
    "# sep: The delimiter (e.g., '\\t' for tab-separated)\n",
    "# header: Row number to use as column names (e.g., header=None)\n",
    "# names: List of column names to use\n",
    "# index_col: Column to use as the row index\n",
    "# usecols: List of columns to read\n",
    "# na_values: Strings to recognize as NaN (e.g., 'Missing', 'N/A')\n",
    "\n",
    "df_csv_options = pd.read_csv(\n",
    "    io.StringIO(csv_data),\n",
    "    index_col='id',            # Use 'id' column as the index\n",
    "    na_values=['', 'NA']      # Treat empty strings as 'Not a Number'\n",
    ")\n",
    "print(\"\\n--- Read from CSV with options ---\")\n",
    "print(df_csv_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1d9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Read from Excel ---\n",
      "      Name  Age         City  Salary\n",
      "0    Alice   25     New York   70000\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n"
     ]
    }
   ],
   "source": [
    "# We need to simulate an Excel file. We'll create one, read it, then delete it.\n",
    "excel_file = 'temp_lab_data.xlsx'\n",
    "df.to_excel(excel_file, sheet_name='Employees', index=False)\n",
    "\n",
    "# Read from Excel\n",
    "# In real life: df_excel = pd.read_excel('my_data.xlsx')\n",
    "df_excel = pd.read_excel(excel_file)\n",
    "\n",
    "print(\"--- Read from Excel ---\")\n",
    "print(df_excel)\n",
    "\n",
    "# Common parameters for read_excel:\n",
    "# sheet_name: Name or index of the sheet to read (default is 0)\n",
    "# header: Row to use as column names\n",
    "# index_col: Column to use as the index\n",
    "\n",
    "# Clean up the file we created\n",
    "os.remove(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ffae171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame ---\n",
      "    id   name department   salary\n",
      "0  101   John      Sales  50000.0\n",
      "1  102   Jane  Marketing  60000.0\n",
      "2  103  Peter      Sales  55000.0\n",
      "3  104   Mary         HR  45000.0\n",
      "4  105    Tom        NaN  70000.0\n",
      "5  106   Lisa  Marketing      NaN\n",
      "\n",
      "'output_no_index.csv' created (check your file system!)\n",
      "'output.xlsx' created.\n"
     ]
    }
   ],
   "source": [
    "# Use the DataFrame from our CSV example\n",
    "print(\"--- Original DataFrame ---\")\n",
    "print(df_csv)\n",
    "\n",
    "# Write to CSV\n",
    "# df_csv.to_csv('output.csv')\n",
    "\n",
    "# A very important parameter is index=False\n",
    "# By default, Pandas will write the index (0, 1, 2...) as a new column.\n",
    "# We usually don't want this.\n",
    "df_csv.to_csv('output_no_index.csv', index=False)\n",
    "print(\"\\n'output_no_index.csv' created (check your file system!)\")\n",
    "\n",
    "# Write to Excel\n",
    "df_csv.to_excel('output.xlsx', sheet_name='Data', index=False)\n",
    "print(\"'output.xlsx' created.\")\n",
    "\n",
    "# Clean up\n",
    "os.remove('output_no_index.csv')\n",
    "os.remove('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc9d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame ---\n",
      "      Name  Age         City  Salary\n",
      "0    Alice   25     New York   70000\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n"
     ]
    }
   ],
   "source": [
    "# Let's use our sample DataFrame 'df' from the beginning\n",
    "print(\"--- Original DataFrame ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3a1faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- .head() ---\n",
      "    Name  Age         City  Salary\n",
      "0  Alice   25     New York   70000\n",
      "1    Bob   30  Los Angeles   80000\n",
      "\n",
      "--- .tail() ---\n",
      "      Name  Age     City  Salary\n",
      "2  Charlie   35  Chicago   90000\n",
      "3    David   40  Houston  100000\n",
      "\n",
      "--- .info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    4 non-null      object\n",
      " 1   Age     4 non-null      int64 \n",
      " 2   City    4 non-null      object\n",
      " 3   Salary  4 non-null      int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 260.0+ bytes\n",
      "\n",
      "--- .describe() ---\n",
      "             Age         Salary\n",
      "count   4.000000       4.000000\n",
      "mean   32.500000   85000.000000\n",
      "std     6.454972   12909.944487\n",
      "min    25.000000   70000.000000\n",
      "25%    28.750000   77500.000000\n",
      "50%    32.500000   85000.000000\n",
      "75%    36.250000   92500.000000\n",
      "max    40.000000  100000.000000\n",
      "\n",
      "--- .describe(include='all') ---\n",
      "         Name        Age      City         Salary\n",
      "count       4   4.000000         4       4.000000\n",
      "unique      4        NaN         4            NaN\n",
      "top     Alice        NaN  New York            NaN\n",
      "freq        1        NaN         1            NaN\n",
      "mean      NaN  32.500000       NaN   85000.000000\n",
      "std       NaN   6.454972       NaN   12909.944487\n",
      "min       NaN  25.000000       NaN   70000.000000\n",
      "25%       NaN  28.750000       NaN   77500.000000\n",
      "50%       NaN  32.500000       NaN   85000.000000\n",
      "75%       NaN  36.250000       NaN   92500.000000\n",
      "max       NaN  40.000000       NaN  100000.000000\n",
      "\n",
      "--- .shape ---\n",
      "(4, 4)\n",
      "\n",
      "--- .columns ---\n",
      "Index(['Name', 'Age', 'City', 'Salary'], dtype='object')\n",
      "\n",
      "--- .dtypes ---\n",
      "Name      object\n",
      "Age        int64\n",
      "City      object\n",
      "Salary     int64\n",
      "dtype: object\n",
      "\n",
      "--- .unique() (for 'City' column) ---\n",
      "['New York' 'Los Angeles' 'Chicago' 'Houston']\n",
      "\n",
      "--- .value_counts() (for 'City' column) ---\n",
      "City\n",
      "New York       1\n",
      "Los Angeles    1\n",
      "Chicago        1\n",
      "Houston        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the first N rows (default 5)\n",
    "print(\"--- .head() ---\")\n",
    "print(df.head(2)) # Show first 2 rows\n",
    "\n",
    "# Get the last N rows (default 5)\n",
    "print(\"\\n--- .tail() ---\")\n",
    "print(df.tail(2)) # Show last 2 rows\n",
    "\n",
    "# Get a concise summary of the DataFrame\n",
    "# This is CRITICAL. It shows:\n",
    "# 1. Index and Column info\n",
    "# 2. Non-null counts (how much data is missing)\n",
    "# 3. Data types (dtypes)\n",
    "# 4. Memory usage\n",
    "print(\"\\n--- .info() ---\")\n",
    "df.info()\n",
    "\n",
    "# Get a statistical summary for numerical columns\n",
    "# Shows: count, mean, std dev, min, max, and quartiles\n",
    "print(\"\\n--- .describe() ---\")\n",
    "print(df.describe())\n",
    "\n",
    "# Get a statistical summary for all columns (including categorical)\n",
    "print(\"\\n--- .describe(include='all') ---\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Get the dimensions (rows, columns)\n",
    "print(\"\\n--- .shape ---\")\n",
    "print(df.shape)\n",
    "\n",
    "# Get column names\n",
    "print(\"\\n--- .columns ---\")\n",
    "print(df.columns)\n",
    "\n",
    "# Get data types\n",
    "print(\"\\n--- .dtypes ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Get unique values in a Series\n",
    "print(\"\\n--- .unique() (for 'City' column) ---\")\n",
    "print(df['City'].unique())\n",
    "\n",
    "# Get value counts for a Series\n",
    "print(\"\\n--- .value_counts() (for 'City' column) ---\")\n",
    "print(df['City'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de8a69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Select single column 'Name' (as Series) ---\n",
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "Name: Name, dtype: object\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "--- Dot notation 'df.Name' ---\n",
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "Name: Name, dtype: object\n",
      "\n",
      "--- Select multiple columns 'Name' and 'Salary' ---\n",
      "      Name  Salary\n",
      "0    Alice   70000\n",
      "1      Bob   80000\n",
      "2  Charlie   90000\n",
      "3    David  100000\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Select a single column (returns a Series)\n",
    "print(\"--- Select single column 'Name' (as Series) ---\")\n",
    "names = df['Name']\n",
    "print(names)\n",
    "print(\"Type:\", type(names))\n",
    "\n",
    "# Alternative: dot notation (BE CAREFUL)\n",
    "# - Only works if column name has no spaces/special chars\n",
    "# - Only works if column name doesn't conflict with a DataFrame method (e.g., 'count')\n",
    "# - It's generally safer to use bracket notation.\n",
    "print(\"\\n--- Dot notation 'df.Name' ---\")\n",
    "print(df.Name)\n",
    "\n",
    "# Select multiple columns (returns a DataFrame)\n",
    "# Note the double brackets: df[ ['col1', 'col2'] ]\n",
    "print(\"\\n--- Select multiple columns 'Name' and 'Salary' ---\")\n",
    "sub_df = df[['Name', 'Salary']]\n",
    "print(sub_df)\n",
    "print(\"Type:\", type(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175295f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Select rows 1 and 2 (index 1 up to 3) ---\n",
      "      Name  Age         City  Salary\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n"
     ]
    }
   ],
   "source": [
    "# Select rows by slice (like Python lists)\n",
    "print(\"--- Select rows 1 and 2 (index 1 up to 3) ---\")\n",
    "print(df[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cd041e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Custom Index DataFrame ---\n",
      "         Name  Age         City  Salary\n",
      "emp1    Alice   25     New York   70000\n",
      "emp2      Bob   30  Los Angeles   80000\n",
      "emp3  Charlie   35      Chicago   90000\n",
      "emp4    David   40      Houston  100000\n",
      "\n",
      "--- .loc['emp2'] (as Series) ---\n",
      "Name              Bob\n",
      "Age                30\n",
      "City      Los Angeles\n",
      "Salary          80000\n",
      "Name: emp2, dtype: object\n",
      "\n",
      "--- .loc[['emp1', 'emp3']] ---\n",
      "         Name  Age      City  Salary\n",
      "emp1    Alice   25  New York   70000\n",
      "emp3  Charlie   35   Chicago   90000\n",
      "\n",
      "--- .loc['emp1':'emp3'] (inclusive) ---\n",
      "         Name  Age         City  Salary\n",
      "emp1    Alice   25     New York   70000\n",
      "emp2      Bob   30  Los Angeles   80000\n",
      "emp3  Charlie   35      Chicago   90000\n",
      "\n",
      "--- .loc['emp2', 'Name'] (single value) ---\n",
      "Bob\n",
      "\n",
      "--- .loc[['emp1', 'emp4'], ['Name', 'Salary']] ---\n",
      "       Name  Salary\n",
      "emp1  Alice   70000\n",
      "emp4  David  100000\n",
      "\n",
      "--- .loc[:, ['Name', 'City']] (all rows) ---\n",
      "         Name         City\n",
      "emp1    Alice     New York\n",
      "emp2      Bob  Los Angeles\n",
      "emp3  Charlie      Chicago\n",
      "emp4    David      Houston\n",
      "\n",
      "\n",
      "--- Original DataFrame (for .iloc) ---\n",
      "      Name  Age         City  Salary\n",
      "0    Alice   25     New York   70000\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n",
      "\n",
      "--- .iloc[1] (row at position 1) ---\n",
      "Name              Bob\n",
      "Age                30\n",
      "City      Los Angeles\n",
      "Salary          80000\n",
      "Name: 1, dtype: object\n",
      "\n",
      "--- .iloc[[0, 2]] (rows at pos 0 and 2) ---\n",
      "      Name  Age      City  Salary\n",
      "0    Alice   25  New York   70000\n",
      "2  Charlie   35   Chicago   90000\n",
      "\n",
      "--- .iloc[0:2] (rows 0 up to 2, exclusive) ---\n",
      "    Name  Age         City  Salary\n",
      "0  Alice   25     New York   70000\n",
      "1    Bob   30  Los Angeles   80000\n",
      "\n",
      "--- .iloc[1, 0] (row 1, col 0) ---\n",
      "Bob\n",
      "\n",
      "--- .iloc[[0, 3], [0, 2]] (rows 0,3 and cols 0,2) ---\n",
      "    Name      City\n",
      "0  Alice  New York\n",
      "3  David   Houston\n",
      "\n",
      "--- .iloc[1:3, :] (rows 1,2, all cols) ---\n",
      "      Name  Age         City  Salary\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Custom Index DataFrame ---\")\n",
    "print(df_custom_index)\n",
    "\n",
    "# --- Using .loc[] (Label-based) ---\n",
    "\n",
    "# Select a single row (returns a Series)\n",
    "print(\"\\n--- .loc['emp2'] (as Series) ---\")\n",
    "print(df_custom_index.loc['emp2'])\n",
    "\n",
    "# Select multiple rows (returns a DataFrame)\n",
    "print(\"\\n--- .loc[['emp1', 'emp3']] ---\")\n",
    "print(df_custom_index.loc[['emp1', 'emp3']])\n",
    "\n",
    "# Select a range of rows (inclusive!)\n",
    "# This is a key difference from Python slicing. .loc is INCLUSIVE.\n",
    "print(\"\\n--- .loc['emp1':'emp3'] (inclusive) ---\")\n",
    "print(df_custom_index.loc['emp1':'emp3'])\n",
    "\n",
    "# Select rows and columns\n",
    "print(\"\\n--- .loc['emp2', 'Name'] (single value) ---\")\n",
    "print(df_custom_index.loc['emp2', 'Name'])\n",
    "\n",
    "print(\"\\n--- .loc[['emp1', 'emp4'], ['Name', 'Salary']] ---\")\n",
    "print(df_custom_index.loc[['emp1', 'emp4'], ['Name', 'Salary']])\n",
    "\n",
    "# Select all rows for specific columns\n",
    "print(\"\\n--- .loc[:, ['Name', 'City']] (all rows) ---\")\n",
    "print(df_custom_index.loc[:, ['Name', 'City']])\n",
    "\n",
    "\n",
    "# --- Using .iloc[] (Integer-position-based) ---\n",
    "# We'll use the original 'df' with default 0, 1, 2... index\n",
    "print(\"\\n\\n--- Original DataFrame (for .iloc) ---\")\n",
    "print(df)\n",
    "\n",
    "# Select a single row (index 1)\n",
    "print(\"\\n--- .iloc[1] (row at position 1) ---\")\n",
    "print(df.iloc[1])\n",
    "\n",
    "# Select multiple rows\n",
    "print(\"\\n--- .iloc[[0, 2]] (rows at pos 0 and 2) ---\")\n",
    "print(df.iloc[[0, 2]])\n",
    "\n",
    "# Select a range of rows (exclusive!)\n",
    "# This works just like standard Python slicing.\n",
    "print(\"\\n--- .iloc[0:2] (rows 0 up to 2, exclusive) ---\")\n",
    "print(df.iloc[0:2]) # Rows at pos 0 and 1\n",
    "\n",
    "# Select rows and columns\n",
    "print(\"\\n--- .iloc[1, 0] (row 1, col 0) ---\")\n",
    "print(df.iloc[1, 0]) # Bob\n",
    "\n",
    "print(\"\\n--- .iloc[[0, 3], [0, 2]] (rows 0,3 and cols 0,2) ---\")\n",
    "print(df.iloc[[0, 3], [0, 2]]) # Alice/David, Name/City\n",
    "\n",
    "# Select all columns for specific rows\n",
    "print(\"\\n--- .iloc[1:3, :] (rows 1,2, all cols) ---\")\n",
    "print(df.iloc[1:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd7d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame ---\n",
      "      Name  Age         City  Salary\n",
      "0    Alice   25     New York   70000\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n",
      "\n",
      "--- Boolean Series (Age > 30) ---\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "Name: Age, dtype: bool\n",
      "\n",
      "--- DataFrame where Age > 30 ---\n",
      "      Name  Age     City  Salary\n",
      "2  Charlie   35  Chicago   90000\n",
      "3    David   40  Houston  100000\n",
      "\n",
      "--- DataFrame where Age > 30 (one line) ---\n",
      "      Name  Age     City  Salary\n",
      "2  Charlie   35  Chicago   90000\n",
      "3    David   40  Houston  100000\n",
      "\n",
      "--- Age > 30 AND City == 'Chicago' ---\n",
      "      Name  Age     City  Salary\n",
      "2  Charlie   35  Chicago   90000\n",
      "\n",
      "--- Salary < 80000 OR City == 'New York' ---\n",
      "    Name  Age      City  Salary\n",
      "0  Alice   25  New York   70000\n",
      "\n",
      "--- City is 'New York' or 'Houston' (using .isin()) ---\n",
      "    Name  Age      City  Salary\n",
      "0  Alice   25  New York   70000\n",
      "3  David   40   Houston  100000\n",
      "\n",
      "--- Age between 30 and 40 (inclusive) ---\n",
      "      Name  Age         City  Salary\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# 1. Create a boolean Series\n",
    "condition = df['Age'] > 30\n",
    "print(\"\\n--- Boolean Series (Age > 30) ---\")\n",
    "print(condition)\n",
    "\n",
    "# 2. Pass that Series to the DataFrame\n",
    "print(\"\\n--- DataFrame where Age > 30 ---\")\n",
    "print(df[df['Age'] > 30])\n",
    "\n",
    "# You can (and usually will) do this in one line:\n",
    "print(\"\\n--- DataFrame where Age > 30 (one line) ---\")\n",
    "print(df[df['Age'] > 30])\n",
    "\n",
    "# More complex conditions\n",
    "# & = AND\n",
    "# | = OR\n",
    "# ~ = NOT\n",
    "# **IMPORTANT**: You MUST use parentheses for each condition.\n",
    "\n",
    "# Condition: Age > 30 AND City == 'Chicago'\n",
    "print(\"\\n--- Age > 30 AND City == 'Chicago' ---\")\n",
    "cond1 = df['Age'] > 30\n",
    "cond2 = df['City'] == 'Chicago'\n",
    "print(df[cond1 & cond2])\n",
    "\n",
    "# Condition: Salary < 80000 OR City == 'New York'\n",
    "print(\"\\n--- Salary < 80000 OR City == 'New York' ---\")\n",
    "print(df[(df['Salary'] < 80000) | (df['City'] == 'New York')])\n",
    "\n",
    "# Using .isin() for multiple ORs\n",
    "print(\"\\n--- City is 'New York' or 'Houston' (using .isin()) ---\")\n",
    "cities = ['New York', 'Houston']\n",
    "print(df[df['City'].isin(cities)])\n",
    "\n",
    "# Using .between() for ranges\n",
    "print(\"\\n--- Age between 30 and 40 (inclusive) ---\")\n",
    "print(df[df['Age'].between(30, 40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53970737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Messy DataFrame ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "4    Alice      25   70000.0           HR\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50       NaN         None\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Name        8 non-null      object \n",
      " 1   Age         8 non-null      object \n",
      " 2   Salary      7 non-null      float64\n",
      " 3   Department  7 non-null      object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 388.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "messy_data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Alice', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, 35, 40, 25, 28, 50, 'Thirty'],\n",
    "    'Salary': [70000, 80000, 90000, 100000, 70000, 65000, None, 85000],\n",
    "    'Department': ['HR', 'Engineering', 'Sales', 'Engineering', 'HR', 'Sales', None, 'HR']\n",
    "}\n",
    "df_messy = pd.DataFrame(messy_data)\n",
    "print(\"--- Messy DataFrame ---\")\n",
    "print(df_messy)\n",
    "df_messy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe2783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Is Null? (Boolean) ---\n",
      "    Name    Age  Salary  Department\n",
      "0  False  False   False       False\n",
      "1  False  False   False       False\n",
      "2  False  False   False       False\n",
      "3  False  False   False       False\n",
      "4  False  False   False       False\n",
      "5  False  False   False       False\n",
      "6  False  False    True        True\n",
      "7  False  False   False       False\n",
      "\n",
      "--- Sum of nulls per column ---\n",
      "Name          0\n",
      "Age           0\n",
      "Salary        1\n",
      "Department    1\n",
      "dtype: int64\n",
      "\n",
      "--- Dropping rows with any NaN ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "4    Alice      25   70000.0           HR\n",
      "5      Eve      28   65000.0        Sales\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- Dropping columns with any NaN ---\n",
      "      Name     Age\n",
      "0    Alice      25\n",
      "1      Bob      30\n",
      "2  Charlie      35\n",
      "3    David      40\n",
      "4    Alice      25\n",
      "5      Eve      28\n",
      "6    Frank      50\n",
      "7    Grace  Thirty\n",
      "\n",
      "--- Dropping rows if ALL are NaN ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "4    Alice      25   70000.0           HR\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50       NaN         None\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- Filling Salary NaN with 0 ---\n",
      "0     70000.0\n",
      "1     80000.0\n",
      "2     90000.0\n",
      "3    100000.0\n",
      "4     70000.0\n",
      "5     65000.0\n",
      "6         0.0\n",
      "7     85000.0\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "Mean salary: 80000.0\n",
      "--- Filling Salary NaN with mean ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "4    Alice      25   70000.0           HR\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50   80000.0         None\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- Filling Department NaN with 'Unassigned' ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "4    Alice      25   70000.0           HR\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50   80000.0   Unassigned\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- Forward-fill (ffill) ---\n",
      "0     70000.0\n",
      "1     80000.0\n",
      "2     90000.0\n",
      "3    100000.0\n",
      "4     70000.0\n",
      "5     65000.0\n",
      "6     65000.0\n",
      "7     85000.0\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "--- Backward-fill (bfill) ---\n",
      "0     70000.0\n",
      "1     80000.0\n",
      "2     90000.0\n",
      "3    100000.0\n",
      "4     70000.0\n",
      "5     65000.0\n",
      "6     85000.0\n",
      "7     85000.0\n",
      "Name: Salary, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rc/v7spqyl57gl721yw5q0dhn_00000gn/T/ipykernel_63313/3910145050.py:45: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(df_messy['Salary'].fillna(method='ffill'))\n",
      "/var/folders/rc/v7spqyl57gl721yw5q0dhn_00000gn/T/ipykernel_63313/3910145050.py:49: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(df_messy['Salary'].fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "# 1. Detect missing data\n",
    "print(\"\\n--- Is Null? (Boolean) ---\")\n",
    "print(df_messy.isnull())\n",
    "\n",
    "print(\"\\n--- Sum of nulls per column ---\")\n",
    "print(df_messy.isnull().sum())\n",
    "\n",
    "# 2. Drop missing data\n",
    "# .dropna() removes rows (axis=0) that contain at least one NaN.\n",
    "print(\"\\n--- Dropping rows with any NaN ---\")\n",
    "print(df_messy.dropna())\n",
    "\n",
    "# Drop columns with any NaN\n",
    "print(\"\\n--- Dropping columns with any NaN ---\")\n",
    "print(df_messy.dropna(axis=1))\n",
    "\n",
    "# Drop rows only if all values are NaN\n",
    "print(\"\\n--- Dropping rows if ALL are NaN ---\")\n",
    "print(df_messy.dropna(how='all'))\n",
    "\n",
    "# 3. Fill missing data\n",
    "# .fillna() is much more common than dropping.\n",
    "# We often fill with a 0, the mean, the median, or a specific string.\n",
    "\n",
    "# Fill Salary NaNs with 0\n",
    "print(\"\\n--- Filling Salary NaN with 0 ---\")\n",
    "print(df_messy['Salary'].fillna(0))\n",
    "\n",
    "# Fill Salary NaNs with the mean salary\n",
    "mean_salary = df_messy['Salary'].mean()\n",
    "print(f\"\\nMean salary: {mean_salary}\")\n",
    "print(\"--- Filling Salary NaN with mean ---\")\n",
    "df_filled = df_messy.copy() # Make a copy to not overwrite\n",
    "df_filled['Salary'] = df_filled['Salary'].fillna(mean_salary)\n",
    "print(df_filled)\n",
    "\n",
    "# Fill Department NaNs with a string 'Unassigned'\n",
    "print(\"\\n--- Filling Department NaN with 'Unassigned' ---\")\n",
    "df_filled['Department'] = df_filled['Department'].fillna('Unassigned')\n",
    "print(df_filled)\n",
    "\n",
    "# Forward-fill (ffill): Fills NaN with the value from the preceding row.\n",
    "# Useful for time-series data.\n",
    "print(\"\\n--- Forward-fill (ffill) ---\")\n",
    "print(df_messy['Salary'].fillna(method='ffill'))\n",
    "\n",
    "# Backward-fill (bfill): Fills NaN with the value from the next row.\n",
    "print(\"\\n--- Backward-fill (bfill) ---\")\n",
    "print(df_messy['Salary'].fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "346a34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detecting duplicates ---\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "dtype: bool\n",
      "\n",
      "--- Show duplicate rows ---\n",
      "    Name Age   Salary Department\n",
      "4  Alice  25  70000.0         HR\n",
      "\n",
      "--- Dropping duplicates (keeps first) ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50       NaN         None\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- Dropping duplicates (keeps last) ---\n",
      "      Name     Age    Salary   Department\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "4    Alice      25   70000.0           HR\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50       NaN         None\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- Dropping duplicates based on 'Name' column only ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50       NaN         None\n",
      "7    Grace  Thirty   85000.0           HR\n"
     ]
    }
   ],
   "source": [
    "# 1. Detect duplicates\n",
    "# .duplicated() returns a boolean Series.\n",
    "# 'keep=first' (default): marks all but the first occurrence as True.\n",
    "print(\"\\n--- Detecting duplicates ---\")\n",
    "print(df_messy.duplicated())\n",
    "\n",
    "# To see the full duplicate row:\n",
    "print(\"\\n--- Show duplicate rows ---\")\n",
    "print(df_messy[df_messy.duplicated()])\n",
    "\n",
    "# 2. Drop duplicates\n",
    "# .drop_duplicates() removes the duplicates.\n",
    "print(\"\\n--- Dropping duplicates (keeps first) ---\")\n",
    "df_no_dupes = df_messy.drop_duplicates()\n",
    "print(df_no_dupes)\n",
    "\n",
    "# Keep the last occurrence instead\n",
    "print(\"\\n--- Dropping duplicates (keeps last) ---\")\n",
    "print(df_messy.drop_duplicates(keep='last'))\n",
    "\n",
    "# Drop duplicates based on a subset of columns\n",
    "print(\"\\n--- Dropping duplicates based on 'Name' column only ---\")\n",
    "print(df_messy.drop_duplicates(subset=['Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f95b6436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Before fixing 'Age' ---\n",
      "      Name     Age    Salary   Department\n",
      "0    Alice      25   70000.0           HR\n",
      "1      Bob      30   80000.0  Engineering\n",
      "2  Charlie      35   90000.0        Sales\n",
      "3    David      40  100000.0  Engineering\n",
      "5      Eve      28   65000.0        Sales\n",
      "6    Frank      50       NaN         None\n",
      "7    Grace  Thirty   85000.0           HR\n",
      "\n",
      "--- After replacing 'Thirty' ---\n",
      "      Name  Age    Salary   Department\n",
      "0    Alice   25   70000.0           HR\n",
      "1      Bob   30   80000.0  Engineering\n",
      "2  Charlie   35   90000.0        Sales\n",
      "3    David   40  100000.0  Engineering\n",
      "5      Eve   28   65000.0        Sales\n",
      "6    Frank   50       NaN         None\n",
      "7    Grace   30   85000.0           HR\n",
      "\n",
      "--- After .astype() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7 entries, 0 to 7\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Name        7 non-null      object\n",
      " 1   Age         7 non-null      int64 \n",
      " 2   Salary      7 non-null      int64 \n",
      " 3   Department  6 non-null      object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 280.0+ bytes\n",
      "      Name  Age  Salary   Department\n",
      "0    Alice   25   70000           HR\n",
      "1      Bob   30   80000  Engineering\n",
      "2  Charlie   35   90000        Sales\n",
      "3    David   40  100000  Engineering\n",
      "5      Eve   28   65000        Sales\n",
      "6    Frank   50       0         None\n",
      "7    Grace   30   85000           HR\n",
      "\n",
      "--- Using pd.to_numeric(errors='coerce') ---\n",
      "      Name     Age    Salary   Department  Age_numeric\n",
      "0    Alice      25   70000.0           HR         25.0\n",
      "1      Bob      30   80000.0  Engineering         30.0\n",
      "2  Charlie      35   90000.0        Sales         35.0\n",
      "3    David      40  100000.0  Engineering         40.0\n",
      "4    Alice      25   70000.0           HR         25.0\n",
      "5      Eve      28   65000.0        Sales         28.0\n",
      "6    Frank      50       NaN         None         50.0\n",
      "7    Grace  Thirty   85000.0           HR          NaN\n",
      "\n",
      "--- After filling NaN from coercion ---\n",
      "      Name     Age    Salary   Department  Age_numeric\n",
      "0    Alice      25   70000.0           HR    25.000000\n",
      "1      Bob      30   80000.0  Engineering    30.000000\n",
      "2  Charlie      35   90000.0        Sales    35.000000\n",
      "3    David      40  100000.0  Engineering    40.000000\n",
      "4    Alice      25   70000.0           HR    25.000000\n",
      "5      Eve      28   65000.0        Sales    28.000000\n",
      "6    Frank      50       NaN         None    50.000000\n",
      "7    Grace  Thirty   85000.0           HR    33.285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rc/v7spqyl57gl721yw5q0dhn_00000gn/T/ipykernel_63313/1169852087.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_fixed['Age'] = df_fixed['Age'].replace('Thirty', 30)\n"
     ]
    }
   ],
   "source": [
    "# 1. Fix the bad data\n",
    "# We can use .replace() or .loc\n",
    "df_fixed = df_messy.drop_duplicates().copy() # Start from a cleaner slate\n",
    "print(\"\\n--- Before fixing 'Age' ---\")\n",
    "print(df_fixed)\n",
    "\n",
    "df_fixed['Age'] = df_fixed['Age'].replace('Thirty', 30)\n",
    "print(\"\\n--- After replacing 'Thirty' ---\")\n",
    "print(df_fixed)\n",
    "\n",
    "# 2. Convert the type\n",
    "# Use .astype() to change the type.\n",
    "# This will fail if there are NaNs or non-numeric strings.\n",
    "# We must fill NaNs first (our 'Salary' column is float due to NaN)\n",
    "df_fixed['Salary'] = df_fixed['Salary'].fillna(0)\n",
    "df_fixed['Salary'] = df_fixed['Salary'].astype(int)\n",
    "\n",
    "df_fixed['Age'] = df_fixed['Age'].astype(int)\n",
    "\n",
    "print(\"\\n--- After .astype() ---\")\n",
    "df_fixed.info()\n",
    "print(df_fixed)\n",
    "\n",
    "# A more robust way: pd.to_numeric\n",
    "# 'errors='coerce'' will turn any un-parseable string into NaN.\n",
    "df_messy['Age_numeric'] = pd.to_numeric(df_messy['Age'], errors='coerce')\n",
    "print(\"\\n--- Using pd.to_numeric(errors='coerce') ---\")\n",
    "print(df_messy)\n",
    "# Now we can fill the NaN\n",
    "df_messy['Age_numeric'] = df_messy['Age_numeric'].fillna(df_messy['Age_numeric'].mean())\n",
    "print(\"\\n--- After filling NaN from coercion ---\")\n",
    "print(df_messy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96bb7523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Original DataFrame ---\n",
      "      Name  Age  Salary   Department\n",
      "0    Alice   25   70000           HR\n",
      "1      Bob   30   80000  Engineering\n",
      "2  Charlie   35   90000        Sales\n",
      "3    David   40  100000  Engineering\n",
      "5      Eve   28   65000        Sales\n",
      "6    Frank   50       0         None\n",
      "7    Grace   30   85000           HR\n",
      "\n",
      "--- After renaming ---\n",
      "  Employee Name  Age  Annual Salary (USD)   Department\n",
      "0         Alice   25                70000           HR\n",
      "1           Bob   30                80000  Engineering\n",
      "2       Charlie   35                90000        Sales\n",
      "3         David   40               100000  Engineering\n",
      "5           Eve   28                65000        Sales\n",
      "6         Frank   50                    0         None\n",
      "7         Grace   30                85000           HR\n",
      "\n",
      "--- Columns cleaned (snake_case) ---\n",
      "Index(['employee_name', 'age', 'annual_salary_', 'department'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Original DataFrame ---\")\n",
    "print(df_fixed)\n",
    "\n",
    "# Use .rename() with a dictionary\n",
    "df_renamed = df_fixed.rename(columns={\n",
    "    'Name': 'Employee Name',\n",
    "    'Salary': 'Annual Salary (USD)'\n",
    "})\n",
    "\n",
    "print(\"\\n--- After renaming ---\")\n",
    "print(df_renamed)\n",
    "\n",
    "# Note: .rename() (like most pandas methods) returns a NEW DataFrame.\n",
    "# To change the original, use inplace=True (but this is discouraged)\n",
    "# df_fixed.rename(columns={'Name': 'Employee Name'}, inplace=True)\n",
    "\n",
    "# A common trick: rename all columns at once to be lower/snake_case\n",
    "df_renamed.columns = df_renamed.columns.str.lower().str.replace(' ', '_').str.replace('(usd)', '', regex=False)\n",
    "print(\"\\n--- Columns cleaned (snake_case) ---\")\n",
    "print(df_renamed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb914fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame ---\n",
      "      Name  Age         City  Salary\n",
      "0    Alice   25     New York   70000\n",
      "1      Bob   30  Los Angeles   80000\n",
      "2  Charlie   35      Chicago   90000\n",
      "3    David   40      Houston  100000\n"
     ]
    }
   ],
   "source": [
    "# Let's use our clean DataFrame 'df'\n",
    "print(\"--- Original DataFrame ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f540a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Added 'Company' column ---\n",
      "      Name  Age         City  Salary   Company\n",
      "0    Alice   25     New York   70000  TechCorp\n",
      "1      Bob   30  Los Angeles   80000  TechCorp\n",
      "2  Charlie   35      Chicago   90000  TechCorp\n",
      "3    David   40      Houston  100000  TechCorp\n",
      "\n",
      "--- Added 'Salary_After_5%_Raise' column ---\n",
      "      Name  Age         City  Salary   Company  Salary_After_5%_Raise\n",
      "0    Alice   25     New York   70000  TechCorp                73500.0\n",
      "1      Bob   30  Los Angeles   80000  TechCorp                84000.0\n",
      "2  Charlie   35      Chicago   90000  TechCorp                94500.0\n",
      "3    David   40      Houston  100000  TechCorp               105000.0\n",
      "\n",
      "--- Modified 'Salary' (10% raise) ---\n",
      "      Name  Age         City    Salary   Company  Salary_After_5%_Raise\n",
      "0    Alice   25     New York   77000.0  TechCorp                73500.0\n",
      "1      Bob   30  Los Angeles   88000.0  TechCorp                84000.0\n",
      "2  Charlie   35      Chicago   99000.0  TechCorp                94500.0\n",
      "3    David   40      Houston  110000.0  TechCorp               105000.0\n",
      "\n",
      "--- Dropped 'Company' column ---\n",
      "      Name  Age         City    Salary  Salary_After_5%_Raise\n",
      "0    Alice   25     New York   77000.0                73500.0\n",
      "1      Bob   30  Los Angeles   88000.0                84000.0\n",
      "2  Charlie   35      Chicago   99000.0                94500.0\n",
      "3    David   40      Houston  110000.0               105000.0\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with a constant value\n",
    "df['Company'] = 'TechCorp'\n",
    "print(\"\\n--- Added 'Company' column ---\")\n",
    "print(df)\n",
    "\n",
    "# Add a new column based on existing columns (Vectorization)\n",
    "# This is FAST. Pandas/NumPy do the loop in C.\n",
    "df['Salary_After_5%_Raise'] = df['Salary'] * 1.05\n",
    "print(\"\\n--- Added 'Salary_After_5%_Raise' column ---\")\n",
    "print(df)\n",
    "\n",
    "# Modify an existing column\n",
    "df['Salary'] = df['Salary'] * 1.10\n",
    "print(\"\\n--- Modified 'Salary' (10% raise) ---\")\n",
    "print(df)\n",
    "\n",
    "# Dropping columns\n",
    "# Use .drop() with axis=1\n",
    "df = df.drop('Company', axis=1)\n",
    "print(\"\\n--- Dropped 'Company' column ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81dde26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Added 'Region' using .map() ---\n",
      "      Name  Age         City    Salary  Salary_After_5%_Raise   Region\n",
      "0    Alice   25     New York   77000.0                73500.0     East\n",
      "1      Bob   30  Los Angeles   88000.0                84000.0     West\n",
      "2  Charlie   35      Chicago   99000.0                94500.0  Midwest\n",
      "3    David   40      Houston  110000.0               105000.0    South\n",
      "\n",
      "--- Added 'Name_Length' using .apply() on Series ---\n",
      "      Name  Age         City    Salary  Salary_After_5%_Raise   Region  \\\n",
      "0    Alice   25     New York   77000.0                73500.0     East   \n",
      "1      Bob   30  Los Angeles   88000.0                84000.0     West   \n",
      "2  Charlie   35      Chicago   99000.0                94500.0  Midwest   \n",
      "3    David   40      Houston  110000.0               105000.0    South   \n",
      "\n",
      "   Name_Length  \n",
      "0            5  \n",
      "1            3  \n",
      "2            7  \n",
      "3            5  \n",
      "\n",
      "--- Added 'Salary_Category' using lambda ---\n",
      "      Name  Age         City    Salary  Salary_After_5%_Raise   Region  \\\n",
      "0    Alice   25     New York   77000.0                73500.0     East   \n",
      "1      Bob   30  Los Angeles   88000.0                84000.0     West   \n",
      "2  Charlie   35      Chicago   99000.0                94500.0  Midwest   \n",
      "3    David   40      Houston  110000.0               105000.0    South   \n",
      "\n",
      "   Name_Length Salary_Category  \n",
      "0            5             Low  \n",
      "1            3             Low  \n",
      "2            7            High  \n",
      "3            5            High  \n",
      "\n",
      "--- .apply() on DataFrame (axis=0) ---\n",
      "Age                         32.5\n",
      "Salary                   93500.0\n",
      "Salary_After_5%_Raise    89250.0\n",
      "Name_Length                  5.0\n",
      "dtype: float64\n",
      "\n",
      "--- Added 'Age_Salary_Ratio' using .apply(axis=1) ---\n",
      "      Name  Age         City    Salary  Salary_After_5%_Raise   Region  \\\n",
      "0    Alice   25     New York   77000.0                73500.0     East   \n",
      "1      Bob   30  Los Angeles   88000.0                84000.0     West   \n",
      "2  Charlie   35      Chicago   99000.0                94500.0  Midwest   \n",
      "3    David   40      Houston  110000.0               105000.0    South   \n",
      "\n",
      "   Name_Length Salary_Category  Age_Salary_Ratio  \n",
      "0            5             Low       3080.000000  \n",
      "1            3             Low       2933.333333  \n",
      "2            7            High       2828.571429  \n",
      "3            5            High       2750.000000  \n"
     ]
    }
   ],
   "source": [
    "# --- .map() ---\n",
    "# Let's map City names to Regions\n",
    "city_region_map = {\n",
    "    'New York': 'East',\n",
    "    'Los Angeles': 'West',\n",
    "    'Chicago': 'Midwest',\n",
    "    'Houston': 'South'\n",
    "}\n",
    "\n",
    "df['Region'] = df['City'].map(city_region_map)\n",
    "print(\"\\n--- Added 'Region' using .map() ---\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "# --- .apply() on a Series ---\n",
    "# Use a custom function or a lambda function\n",
    "def get_name_length(name):\n",
    "    return len(name)\n",
    "\n",
    "df['Name_Length'] = df['Name'].apply(get_name_length)\n",
    "print(\"\\n--- Added 'Name_Length' using .apply() on Series ---\")\n",
    "print(df)\n",
    "\n",
    "# Same thing with a lambda function (more common)\n",
    "df['Salary_Category'] = df['Salary'].apply(\n",
    "    lambda x: 'High' if x > 90000 else 'Low'\n",
    ")\n",
    "print(\"\\n--- Added 'Salary_Category' using lambda ---\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "# --- .apply() on a DataFrame ---\n",
    "# By default, axis=0 (applies function to each COLUMN)\n",
    "print(\"\\n--- .apply() on DataFrame (axis=0) ---\")\n",
    "# This is like calling .mean() on all numeric columns\n",
    "# Fix: Select only numeric columns before applying np.mean\n",
    "print(df.select_dtypes(include=np.number).apply(np.mean, axis=0))\n",
    "\n",
    "# axis=1 (applies function to each ROW)\n",
    "# The function receives the entire row as a Series\n",
    "def get_age_salary_ratio(row):\n",
    "    # 'row' is a Series where index is column names\n",
    "    return row['Salary'] / row['Age']\n",
    "\n",
    "df['Age_Salary_Ratio'] = df.apply(get_age_salary_ratio, axis=1)\n",
    "print(\"\\n--- Added 'Age_Salary_Ratio' using .apply(axis=1) ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a5f1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using .str accessor ---\n",
      "Lower case names:  0      alice\n",
      "1        bob\n",
      "2    charlie\n",
      "3      david\n",
      "Name: Name, dtype: object\n",
      "Does name contain 'li'?  0     True\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "Name: Name, dtype: bool\n",
      "Replace 'e' with 'X':  0      AlicX\n",
      "1        Bob\n",
      "2    CharliX\n",
      "3      David\n",
      "Name: Name, dtype: object\n",
      "\n",
      "--- Splitting a column ---\n",
      "      FullName\n",
      "0    Doe, John\n",
      "1  Smith, Jane\n",
      "2   Brown, Jim\n",
      "  LastName FirstName\n",
      "0      Doe      John\n",
      "1    Smith      Jane\n",
      "2    Brown       Jim\n",
      "\n",
      "--- After splitting and joining ---\n",
      "      FullName LastName FirstName\n",
      "0    Doe, John      Doe      John\n",
      "1  Smith, Jane    Smith      Jane\n",
      "2   Brown, Jim    Brown       Jim\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Using .str accessor ---\")\n",
    "print(\"Lower case names: \", df['Name'].str.lower())\n",
    "print(\"Does name contain 'li'? \", df['Name'].str.contains('li'))\n",
    "print(\"Replace 'e' with 'X': \", df['Name'].str.replace('e', 'X'))\n",
    "\n",
    "# Example: Split and extract\n",
    "df_split = pd.DataFrame({'FullName': ['Doe, John', 'Smith, Jane', 'Brown, Jim']})\n",
    "print(\"\\n--- Splitting a column ---\")\n",
    "print(df_split)\n",
    "split_names = df_split['FullName'].str.split(', ', expand=True)\n",
    "split_names.columns = ['LastName', 'FirstName']\n",
    "print(split_names)\n",
    "\n",
    "# We can join this back to the original\n",
    "df_split = pd.concat([df_split, split_names], axis=1)\n",
    "print(\"\\n--- After splitting and joining ---\")\n",
    "print(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec426bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Grouping DataFrame ---\n",
      "    Department   Name  Salary  Years\n",
      "0        Sales   John   50000      3\n",
      "1  Engineering   Jane   90000      5\n",
      "2        Sales  Peter   55000      4\n",
      "3    Marketing   Mary   60000      2\n",
      "4  Engineering    Tom   95000      8\n",
      "5        Sales   Lisa   70000      6\n",
      "6           HR    Sue   45000      1\n"
     ]
    }
   ],
   "source": [
    "data_grouped = {\n",
    "    'Department': ['Sales', 'Engineering', 'Sales', 'Marketing', 'Engineering', 'Sales', 'HR'],\n",
    "    'Name': ['John', 'Jane', 'Peter', 'Mary', 'Tom', 'Lisa', 'Sue'],\n",
    "    'Salary': [50000, 90000, 55000, 60000, 95000, 70000, 45000],\n",
    "    'Years': [3, 5, 4, 2, 8, 6, 1]\n",
    "}\n",
    "df_group = pd.DataFrame(data_grouped)\n",
    "print(\"--- Grouping DataFrame ---\")\n",
    "print(df_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fe7170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GroupBy Object ---\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x11554f4d0>\n",
      "\n",
      "--- Mean salary by department ---\n",
      "Department\n",
      "Engineering    92500.000000\n",
      "HR             45000.000000\n",
      "Marketing      60000.000000\n",
      "Sales          58333.333333\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "--- Total salary by department ---\n",
      "Department\n",
      "Engineering    185000\n",
      "HR              45000\n",
      "Marketing       60000\n",
      "Sales          175000\n",
      "Name: Salary, dtype: int64\n",
      "\n",
      "--- Count of employees by department ---\n",
      "Department\n",
      "Engineering    2\n",
      "HR             1\n",
      "Marketing      1\n",
      "Sales          3\n",
      "Name: Name, dtype: int64\n",
      "Department\n",
      "Engineering    2\n",
      "HR             1\n",
      "Marketing      1\n",
      "Sales          3\n",
      "dtype: int64\n",
      "\n",
      "--- .describe() by department ---\n",
      "             count          mean           std      min      25%      50%  \\\n",
      "Department                                                                  \n",
      "Engineering    2.0  92500.000000   3535.533906  90000.0  91250.0  92500.0   \n",
      "HR             1.0  45000.000000           NaN  45000.0  45000.0  45000.0   \n",
      "Marketing      1.0  60000.000000           NaN  60000.0  60000.0  60000.0   \n",
      "Sales          3.0  58333.333333  10408.329997  50000.0  52500.0  55000.0   \n",
      "\n",
      "                 75%      max  \n",
      "Department                     \n",
      "Engineering  93750.0  95000.0  \n",
      "HR           45000.0  45000.0  \n",
      "Marketing    60000.0  60000.0  \n",
      "Sales        62500.0  70000.0  \n"
     ]
    }
   ],
   "source": [
    "# Create a groupby object\n",
    "# This object is \"lazy\" - it hasn't computed anything yet.\n",
    "dept_group = df_group.groupby('Department')\n",
    "print(\"\\n--- GroupBy Object ---\")\n",
    "print(dept_group)\n",
    "\n",
    "# Now, we apply an aggregation\n",
    "print(\"\\n--- Mean salary by department ---\")\n",
    "print(dept_group['Salary'].mean())\n",
    "\n",
    "print(\"\\n--- Total salary by department ---\")\n",
    "print(dept_group['Salary'].sum())\n",
    "\n",
    "print(\"\\n--- Count of employees by department ---\")\n",
    "# .count() counts non-NaN values\n",
    "# .size() counts total rows (including NaN)\n",
    "print(dept_group['Name'].count())\n",
    "# or\n",
    "print(dept_group.size())\n",
    "\n",
    "# Get a quick summary\n",
    "print(\"\\n--- .describe() by department ---\")\n",
    "print(dept_group['Salary'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8709137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multiple aggregations on Salary ---\n",
      "                sum          mean           std  count\n",
      "Department                                            \n",
      "Engineering  185000  92500.000000   3535.533906      2\n",
      "HR            45000  45000.000000           NaN      1\n",
      "Marketing     60000  60000.000000           NaN      1\n",
      "Sales        175000  58333.333333  10408.329997      3\n",
      "\n",
      "--- Different aggregations for different columns ---\n",
      "                   Salary     Years    \n",
      "                     mean      mean max\n",
      "Department                             \n",
      "Engineering  92500.000000  6.500000   8\n",
      "HR           45000.000000  1.000000   1\n",
      "Marketing    60000.000000  2.000000   2\n",
      "Sales        58333.333333  4.333333   6\n",
      "\n",
      "--- Named aggregations ---\n",
      "              Mean Salary  Max Experience\n",
      "Department                               \n",
      "Engineering  92500.000000               8\n",
      "HR           45000.000000               1\n",
      "Marketing    60000.000000               2\n",
      "Sales        58333.333333               6\n"
     ]
    }
   ],
   "source": [
    "# Apply multiple aggregations at once\n",
    "print(\"\\n--- Multiple aggregations on Salary ---\")\n",
    "print(dept_group['Salary'].agg(['sum', 'mean', 'std', 'count']))\n",
    "\n",
    "# Apply different aggregations to different columns\n",
    "# We pass a dictionary\n",
    "aggregations = {\n",
    "    'Salary': 'mean',\n",
    "    'Years': ['mean', 'max']\n",
    "}\n",
    "print(\"\\n--- Different aggregations for different columns ---\")\n",
    "print(dept_group.agg(aggregations))\n",
    "\n",
    "# You can even rename the output columns\n",
    "# The key should be the NEW column name, and the value is (original_column, aggregation)\n",
    "aggregations_named = {\n",
    "    'Mean Salary': ('Salary', 'mean'),\n",
    "    'Max Experience': ('Years', 'max')\n",
    "}\n",
    "print(\"\\n--- Named aggregations ---\")\n",
    "print(dept_group.agg(**aggregations_named))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7cbe260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame with Location ---\n",
      "    Department   Name  Salary  Years Location\n",
      "0        Sales   John   50000      3      USA\n",
      "1  Engineering   Jane   90000      5      CAN\n",
      "2        Sales  Peter   55000      4      USA\n",
      "3    Marketing   Mary   60000      2      USA\n",
      "4  Engineering    Tom   95000      8      CAN\n",
      "5        Sales   Lisa   70000      6      USA\n",
      "6           HR    Sue   45000      1      CAN\n",
      "\n",
      "--- Mean salary by Dept and Location ---\n",
      "Department   Location\n",
      "Engineering  CAN         92500.000000\n",
      "HR           CAN         45000.000000\n",
      "Marketing    USA         60000.000000\n",
      "Sales        USA         58333.333333\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "--- Same, but with as_index=False ---\n",
      "    Department Location        Salary\n",
      "0  Engineering      CAN  92500.000000\n",
      "1           HR      CAN  45000.000000\n",
      "2    Marketing      USA  60000.000000\n",
      "3        Sales      USA  58333.333333\n"
     ]
    }
   ],
   "source": [
    "# Let's add another categorical column\n",
    "df_group['Location'] = ['USA', 'CAN', 'USA', 'USA', 'CAN', 'USA', 'CAN']\n",
    "print(\"\\n--- DataFrame with Location ---\")\n",
    "print(df_group)\n",
    "\n",
    "# Group by Department, then Location\n",
    "multi_group = df_group.groupby(['Department', 'Location'])\n",
    "\n",
    "print(\"\\n--- Mean salary by Dept and Location ---\")\n",
    "print(multi_group['Salary'].mean())\n",
    "\n",
    "# This results in a Series with a MultiIndex.\n",
    "# To make it a flat DataFrame, use as_index=False\n",
    "print(\"\\n--- Same, but with as_index=False ---\")\n",
    "print(df_group.groupby(['Department', 'Location'], as_index=False)['Salary'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94d9691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- df1 --- \n",
      "     id     Name\n",
      "0  A01    Alice\n",
      "1  A02      Bob\n",
      "2  A03  Charlie\n",
      "3  A04    David\n",
      "\n",
      "--- df2 --- \n",
      "     id   Name\n",
      "0  A05    Eve\n",
      "1  A06  Frank\n",
      "2  A07  Grace\n",
      "\n",
      "--- df3_info --- \n",
      "     id  Salary\n",
      "0  A01   70000\n",
      "1  A02   80000\n",
      "2  A03   90000\n",
      "3  A04  100000\n",
      "\n",
      "--- df4_dept --- \n",
      "     id Department\n",
      "0  A01         HR\n",
      "1  A02        Eng\n",
      "2  A03      Sales\n",
      "3  A05        Eng\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'id': ['A01', 'A02', 'A03', 'A04'],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'id': ['A05', 'A06', 'A07'],\n",
    "    'Name': ['Eve', 'Frank', 'Grace']\n",
    "})\n",
    "\n",
    "df3_info = pd.DataFrame({\n",
    "    'id': ['A01', 'A02', 'A03', 'A04'],\n",
    "    'Salary': [70000, 80000, 90000, 100000]\n",
    "})\n",
    "\n",
    "df4_dept = pd.DataFrame({\n",
    "    'id': ['A01', 'A02', 'A03', 'A05'], # Note: A04 missing, A05 added\n",
    "    'Department': ['HR', 'Eng', 'Sales', 'Eng']\n",
    "})\n",
    "\n",
    "print(\"--- df1 --- \\n\", df1)\n",
    "print(\"\\n--- df2 --- \\n\", df2)\n",
    "print(\"\\n--- df3_info --- \\n\", df3_info)\n",
    "print(\"\\n--- df4_dept --- \\n\", df4_dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bee6243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Concatenating rows (axis=0) ---\n",
      "    id     Name\n",
      "0  A01    Alice\n",
      "1  A02      Bob\n",
      "2  A03  Charlie\n",
      "3  A04    David\n",
      "0  A05      Eve\n",
      "1  A06    Frank\n",
      "2  A07    Grace\n",
      "\n",
      "--- Concatenating rows (resetting index) ---\n",
      "    id     Name\n",
      "0  A01    Alice\n",
      "1  A02      Bob\n",
      "2  A03  Charlie\n",
      "3  A04    David\n",
      "4  A05      Eve\n",
      "5  A06    Frank\n",
      "6  A07    Grace\n",
      "\n",
      "--- Concatenating columns (axis=1) ---\n",
      "    id     Name   id  Salary\n",
      "0  A01    Alice  A01   70000\n",
      "1  A02      Bob  A02   80000\n",
      "2  A03  Charlie  A03   90000\n",
      "3  A04    David  A04  100000\n"
     ]
    }
   ],
   "source": [
    "# Stack df1 on top of df2 (axis=0, default)\n",
    "print(\"\\n--- Concatenating rows (axis=0) ---\")\n",
    "df_all_rows = pd.concat([df1, df2])\n",
    "print(df_all_rows)\n",
    "\n",
    "# Note the index is preserved (0,1,2,3, 0,1,2). This is usually bad.\n",
    "print(\"\\n--- Concatenating rows (resetting index) ---\")\n",
    "df_all_rows = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_all_rows)\n",
    "\n",
    "# Stack side-by-side (axis=1)\n",
    "# This joins on the index.\n",
    "print(\"\\n--- Concatenating columns (axis=1) ---\")\n",
    "df_side_by_side = pd.concat([df1, df3_info], axis=1)\n",
    "print(df_side_by_side)\n",
    "# This is \"dumb\" - it just puts them together. Notice the duplicate 'id' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c83af538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inner Merge (df1 and df4_dept) ---\n",
      "    id     Name Department\n",
      "0  A01    Alice         HR\n",
      "1  A02      Bob        Eng\n",
      "2  A03  Charlie      Sales\n",
      "\n",
      "--- Left Merge (df1 and df4_dept) ---\n",
      "    id     Name Department\n",
      "0  A01    Alice         HR\n",
      "1  A02      Bob        Eng\n",
      "2  A03  Charlie      Sales\n",
      "3  A04    David        NaN\n",
      "\n",
      "--- Right Merge (df1 and df4_dept) ---\n",
      "    id     Name Department\n",
      "0  A01    Alice         HR\n",
      "1  A02      Bob        Eng\n",
      "2  A03  Charlie      Sales\n",
      "3  A05      NaN        Eng\n",
      "\n",
      "--- Outer Merge (df1 and df4_dept) ---\n",
      "    id     Name Department\n",
      "0  A01    Alice         HR\n",
      "1  A02      Bob        Eng\n",
      "2  A03  Charlie      Sales\n",
      "3  A04    David        NaN\n",
      "4  A05      NaN        Eng\n",
      "\n",
      "--- Merging on different key names ---\n",
      "    id   Name employee_id     Phone\n",
      "0  A01  Alice         A01  555-1234\n",
      "1  A02    Bob         A02  555-5678\n"
     ]
    }
   ],
   "source": [
    "# Inner Join (default)\n",
    "# Keeps only the rows where the key ('id') exists in BOTH DataFrames.\n",
    "print(\"\\n--- Inner Merge (df1 and df4_dept) ---\")\n",
    "# A04 is in df1 but not df4, A05 is in df4 but not df1\n",
    "# So, only A01, A02, A03 will be in the result.\n",
    "inner_merge = pd.merge(df1, df4_dept, on='id', how='inner')\n",
    "print(inner_merge)\n",
    "\n",
    "# Left Join\n",
    "# Keeps all rows from the \"left\" DataFrame (df1) and matches from the \"right\" (df4).\n",
    "print(\"\\n--- Left Merge (df1 and df4_dept) ---\")\n",
    "# A04 will be kept, but its 'Department' will be NaN.\n",
    "left_merge = pd.merge(df1, df4_dept, on='id', how='left')\n",
    "print(left_merge)\n",
    "\n",
    "# Right Join\n",
    "# Keeps all rows from the \"right\" DataFrame (df4) and matches from \"left\" (df1).\n",
    "print(\"\\n--- Right Merge (df1 and df4_dept) ---\")\n",
    "# A05 will be kept, but its 'Name' will be NaN.\n",
    "right_merge = pd.merge(df1, df4_dept, on='id', how='right')\n",
    "print(right_merge)\n",
    "\n",
    "# Outer Join\n",
    "# Keeps all rows from BOTH DataFrames. Fills missing with NaN.\n",
    "print(\"\\n--- Outer Merge (df1 and df4_dept) ---\")\n",
    "# Will contain A01, A02, A03, A04, A05.\n",
    "outer_merge = pd.merge(df1, df4_dept, on='id', how='outer')\n",
    "print(outer_merge)\n",
    "\n",
    "# Merging on different column names\n",
    "df5_data = pd.DataFrame({\n",
    "    'employee_id': ['A01', 'A02'],\n",
    "    'Phone': ['555-1234', '555-5678']\n",
    "})\n",
    "print(\"\\n--- Merging on different key names ---\")\n",
    "print(pd.merge(df1, df5_data, left_on='id', right_on='employee_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0790061b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- df1 (indexed) ---\n",
      "         Name\n",
      "id          \n",
      "A01    Alice\n",
      "A02      Bob\n",
      "A03  Charlie\n",
      "A04    David\n",
      "\n",
      "--- df3 (indexed) ---\n",
      "      Salary\n",
      "id         \n",
      "A01   70000\n",
      "A02   80000\n",
      "A03   90000\n",
      "A04  100000\n",
      "\n",
      "--- Joining on index ---\n",
      "        Name  Salary\n",
      "id                  \n",
      "A01    Alice   70000\n",
      "A02      Bob   80000\n",
      "A03  Charlie   90000\n",
      "A04    David  100000\n"
     ]
    }
   ],
   "source": [
    "# Let's set 'id' as the index for df1 and df3\n",
    "df1_indexed = df1.set_index('id')\n",
    "df3_indexed = df3_info.set_index('id')\n",
    "\n",
    "print(\"\\n--- df1 (indexed) ---\\n\", df1_indexed)\n",
    "print(\"\\n--- df3 (indexed) ---\\n\", df3_indexed)\n",
    "\n",
    "# Now we can .join() them. Default is a left join.\n",
    "print(\"\\n--- Joining on index ---\")\n",
    "print(df1_indexed.join(df3_indexed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba29545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Grouping DataFrame ---\n",
      "    Department   Name  Salary  Years Location\n",
      "0        Sales   John   50000      3      USA\n",
      "1  Engineering   Jane   90000      5      CAN\n",
      "2        Sales  Peter   55000      4      USA\n",
      "3    Marketing   Mary   60000      2      USA\n",
      "4  Engineering    Tom   95000      8      CAN\n",
      "5        Sales   Lisa   70000      6      USA\n",
      "6           HR    Sue   45000      1      CAN\n",
      "\n",
      "--- Groupby result ---\n",
      "Department   Location\n",
      "Engineering  CAN         92500.000000\n",
      "HR           CAN         45000.000000\n",
      "Marketing    USA         60000.000000\n",
      "Sales        USA         58333.333333\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "--- Pivot Table result ---\n",
      "Location         CAN           USA\n",
      "Department                        \n",
      "Engineering  92500.0           NaN\n",
      "HR           45000.0           NaN\n",
      "Marketing        NaN  60000.000000\n",
      "Sales            NaN  58333.333333\n",
      "\n",
      "--- Pivot Table with fill_value and margins ---\n",
      "Location              CAN           USA     Total_Avg\n",
      "Department                                           \n",
      "Engineering  92500.000000      0.000000  92500.000000\n",
      "HR           45000.000000      0.000000  45000.000000\n",
      "Marketing        0.000000  60000.000000  60000.000000\n",
      "Sales            0.000000  58333.333333  58333.333333\n",
      "Total_Avg    76666.666667  58750.000000  66428.571429\n"
     ]
    }
   ],
   "source": [
    "# Let's use our 'df_group' data\n",
    "print(\"--- Grouping DataFrame ---\")\n",
    "print(df_group)\n",
    "\n",
    "# Let's find the average Salary for each Department and Location.\n",
    "# We could use a groupby:\n",
    "print(\"\\n--- Groupby result ---\")\n",
    "print(df_group.groupby(['Department', 'Location'])['Salary'].mean())\n",
    "\n",
    "# Or we can use a pivot_table:\n",
    "# index = rows\n",
    "# columns = columns\n",
    "# values = what to aggregate\n",
    "# aggfunc = how to aggregate (default is mean)\n",
    "print(\"\\n--- Pivot Table result ---\")\n",
    "pivot = pd.pivot_table(\n",
    "    df_group,\n",
    "    values='Salary',\n",
    "    index='Department',\n",
    "    columns='Location',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(pivot)\n",
    "\n",
    "# We can fill NaNs and add margins (totals)\n",
    "print(\"\\n--- Pivot Table with fill_value and margins ---\")\n",
    "pivot_full = pd.pivot_table(\n",
    "    df_group,\n",
    "    values='Salary',\n",
    "    index='Department',\n",
    "    columns='Location',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0,   # Fill missing cells with 0\n",
    "    margins=True,   # Add 'All' (total) row/column\n",
    "    margins_name='Total_Avg'\n",
    ")\n",
    "print(pivot_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abc915b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Original MultiIndex Series ---\n",
      "Department   Location\n",
      "Engineering  CAN         92500.000000\n",
      "HR           CAN         45000.000000\n",
      "Marketing    USA         60000.000000\n",
      "Sales        USA         58333.333333\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "--- .unstack() ---\n",
      "Location         CAN           USA\n",
      "Department                        \n",
      "Engineering  92500.0           NaN\n",
      "HR           45000.0           NaN\n",
      "Marketing        NaN  60000.000000\n",
      "Sales            NaN  58333.333333\n",
      "\n",
      "--- Original 'pivot' DataFrame ---\n",
      "Location         CAN           USA\n",
      "Department                        \n",
      "Engineering  92500.0           NaN\n",
      "HR           45000.0           NaN\n",
      "Marketing        NaN  60000.000000\n",
      "Sales            NaN  58333.333333\n",
      "\n",
      "--- .stack() ---\n",
      "Department   Location\n",
      "Engineering  CAN         92500.000000\n",
      "HR           CAN         45000.000000\n",
      "Marketing    USA         60000.000000\n",
      "Sales        USA         58333.333333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's use our pivot table, which has a MultiIndex if we groupby\n",
    "s = df_group.groupby(['Department', 'Location'])['Salary'].mean()\n",
    "print(\"\\n--- Original MultiIndex Series ---\")\n",
    "print(s)\n",
    "\n",
    "# --- Unstack ---\n",
    "# .unstack() moves the *innermost* index level (Location) to columns.\n",
    "print(\"\\n--- .unstack() ---\")\n",
    "print(s.unstack())\n",
    "\n",
    "# --- Stack ---\n",
    "# Let's use the 'pivot' DataFrame, which is \"wide\"\n",
    "print(\"\\n--- Original 'pivot' DataFrame ---\")\n",
    "print(pivot)\n",
    "\n",
    "# .stack() moves the *column* level (Location) to be the new *innermost* index.\n",
    "print(\"\\n--- .stack() ---\")\n",
    "print(pivot.stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51017119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before conversion ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   date_str  4 non-null      object\n",
      " 1   sales     4 non-null      int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 196.0+ bytes\n",
      "\n",
      "--- After pd.to_datetime() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date_str  4 non-null      object        \n",
      " 1   sales     4 non-null      int64         \n",
      " 2   date      4 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 228.0+ bytes\n",
      "     date_str  sales       date\n",
      "0  2025-01-01    100 2025-01-01\n",
      "1  2025-01-05    150 2025-01-05\n",
      "2  2025-01-10    120 2025-01-10\n",
      "3  2025-01-15    200 2025-01-15\n",
      "\n",
      "--- Extracted components ---\n",
      "     date_str  sales       date day_of_week  month\n",
      "0  2025-01-01    100 2025-01-01   Wednesday      1\n",
      "1  2025-01-05    150 2025-01-05      Sunday      1\n",
      "2  2025-01-10    120 2025-01-10      Friday      1\n",
      "3  2025-01-15    200 2025-01-15   Wednesday      1\n",
      "\n",
      "--- pd.date_range() ---\n",
      "DatetimeIndex(['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04',\n",
      "               '2025-01-05', '2025-01-06', '2025-01-07', '2025-01-08',\n",
      "               '2025-01-09', '2025-01-10'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "# Convert a column of strings to datetime objects\n",
    "df_time = pd.DataFrame({'date_str': ['2025-01-01', '2025-01-05', '2025-01-10', '2025-01-15'],\n",
    "                        'sales': [100, 150, 120, 200]})\n",
    "print(\"--- Before conversion ---\")\n",
    "df_time.info()\n",
    "\n",
    "df_time['date'] = pd.to_datetime(df_time['date_str'])\n",
    "print(\"\\n--- After pd.to_datetime() ---\")\n",
    "df_time.info()\n",
    "print(df_time)\n",
    "\n",
    "# We can now extract components\n",
    "df_time['day_of_week'] = df_time['date'].dt.day_name()\n",
    "df_time['month'] = df_time['date'].dt.month\n",
    "print(\"\\n--- Extracted components ---\")\n",
    "print(df_time)\n",
    "\n",
    "# Create a date range\n",
    "# 'D' = Day, 'M' = Month End, 'MS' = Month Start, 'h' = hour\n",
    "print(\"\\n--- pd.date_range() ---\")\n",
    "date_index = pd.date_range(start='2025-01-01', periods=10, freq='D')\n",
    "print(date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a2ab6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Time Series DataFrame (first 5 rows) ---\n",
      "            data\n",
      "2025-01-01    82\n",
      "2025-01-02    88\n",
      "2025-01-03    89\n",
      "2025-01-04    70\n",
      "2025-01-05    74\n",
      "\n",
      "--- Select '2025-01-05' ---\n",
      "data    74\n",
      "Name: 2025-01-05 00:00:00, dtype: int64\n",
      "\n",
      "--- Slice for a week ---\n",
      "            data\n",
      "2025-01-10    85\n",
      "2025-01-11    59\n",
      "2025-01-12    60\n",
      "2025-01-13    96\n",
      "2025-01-14    66\n",
      "2025-01-15    96\n",
      "2025-01-16    54\n",
      "2025-01-17    98\n",
      "\n",
      "--- Slice for an entire month ---\n",
      "            data\n",
      "2025-02-01    78\n",
      "2025-02-02    89\n",
      "2025-02-03    54\n",
      "2025-02-04    98\n",
      "2025-02-05    55\n",
      "2025-02-06    51\n",
      "2025-02-07    71\n",
      "2025-02-08    89\n",
      "2025-02-09    55\n",
      "2025-02-10    73\n",
      "2025-02-11    96\n",
      "2025-02-12    90\n",
      "2025-02-13    83\n",
      "2025-02-14    96\n",
      "2025-02-15    92\n",
      "2025-02-16    87\n",
      "2025-02-17    70\n",
      "2025-02-18    78\n",
      "2025-02-19    59\n",
      "2025-02-20    71\n",
      "2025-02-21    55\n",
      "2025-02-22    97\n",
      "2025-02-23    54\n",
      "2025-02-24    98\n",
      "2025-02-25    86\n",
      "2025-02-26    91\n",
      "2025-02-27    80\n",
      "2025-02-28    60\n"
     ]
    }
   ],
   "source": [
    "# Create a sample time series DataFrame\n",
    "ts_index = pd.date_range(start='2025-01-01', periods=100, freq='D')\n",
    "data = np.random.randint(50, 100, size=100)\n",
    "ts_df = pd.DataFrame({'data': data}, index=ts_index)\n",
    "print(\"\\n--- Time Series DataFrame (first 5 rows) ---\")\n",
    "print(ts_df.head())\n",
    "\n",
    "# Selection and slicing is now based on dates\n",
    "print(\"\\n--- Select '2025-01-05' ---\")\n",
    "print(ts_df.loc['2025-01-05'])\n",
    "\n",
    "print(\"\\n--- Slice for a week ---\")\n",
    "print(ts_df.loc['2025-01-10':'2025-01-17'])\n",
    "\n",
    "print(\"\\n--- Slice for an entire month ---\")\n",
    "print(ts_df.loc['2025-02']) # Selects all of February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80db6727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Downsampling: Weekly Sum ---\n",
      "            data\n",
      "2025-01-05   403\n",
      "2025-01-12   508\n",
      "2025-01-19   544\n",
      "2025-01-26   559\n",
      "2025-02-02   552\n",
      "2025-02-09   473\n",
      "2025-02-16   617\n",
      "2025-02-23   484\n",
      "2025-03-02   576\n",
      "2025-03-09   553\n",
      "2025-03-16   529\n",
      "2025-03-23   583\n",
      "2025-03-30   512\n",
      "2025-04-06   537\n",
      "2025-04-13   347\n",
      "\n",
      "--- Downsampling: Monthly Mean ---\n",
      "                 data\n",
      "2025-01-31  77.387097\n",
      "2025-02-28  77.000000\n",
      "2025-03-31  77.935484\n",
      "2025-04-30  80.600000\n",
      "\n",
      "--- Upsampling: Daily to 12-hour ---\n",
      "                     data\n",
      "2025-01-01 00:00:00  82.0\n",
      "2025-01-01 12:00:00   NaN\n",
      "2025-01-02 00:00:00  88.0\n",
      "2025-01-02 12:00:00   NaN\n",
      "2025-01-03 00:00:00  89.0\n",
      "2025-01-03 12:00:00   NaN\n",
      "2025-01-04 00:00:00  70.0\n",
      "2025-01-04 12:00:00   NaN\n",
      "2025-01-05 00:00:00  74.0\n",
      "2025-01-05 12:00:00   NaN\n",
      "\n",
      "--- Upsampling with ffill ---\n",
      "                     data\n",
      "2025-01-01 00:00:00    82\n",
      "2025-01-01 12:00:00    82\n",
      "2025-01-02 00:00:00    88\n",
      "2025-01-02 12:00:00    88\n",
      "2025-01-03 00:00:00    89\n",
      "2025-01-03 12:00:00    89\n",
      "2025-01-04 00:00:00    70\n",
      "2025-01-04 12:00:00    70\n",
      "2025-01-05 00:00:00    74\n",
      "2025-01-05 12:00:00    74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rc/v7spqyl57gl721yw5q0dhn_00000gn/T/ipykernel_63313/382181707.py:7: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  print(ts_df.resample('M').mean())\n"
     ]
    }
   ],
   "source": [
    "# Downsample: Get the total (sum) sales per week ('W')\n",
    "print(\"\\n--- Downsampling: Weekly Sum ---\")\n",
    "print(ts_df.resample('W').sum())\n",
    "\n",
    "# Downsample: Get the average (mean) sales per month ('M')\n",
    "print(\"\\n--- Downsampling: Monthly Mean ---\")\n",
    "print(ts_df.resample('M').mean())\n",
    "\n",
    "# Upsampling: From Daily ('D') to 12-hour ('12h')\n",
    "# This creates a lot of NaNs.\n",
    "print(\"\\n--- Upsampling: Daily to 12-hour ---\")\n",
    "print(ts_df.resample('12h').mean().head(10)) # .mean() is arbitrary here\n",
    "\n",
    "# We can fill the NaNs\n",
    "print(\"\\n--- Upsampling with ffill ---\")\n",
    "print(ts_df.resample('12h').ffill().head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
